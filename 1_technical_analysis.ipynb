{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Domain Proyek](#toc1_)    \n",
    "- 2. [Business Understanding](#toc2_)    \n",
    "  - 2.1. [Problem Statements](#toc2_1_)    \n",
    "  - 2.2. [Goals](#toc2_2_)    \n",
    "  - 2.3. [Solution statements](#toc2_3_)    \n",
    "- 3. [Data Understanding](#toc3_)    \n",
    "  - 3.1. [Overview Data](#toc3_1_)    \n",
    "  - 3.2. [Analisis Deskriptif](#toc3_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laporan Proyek Machine Learning - Rizal Fadlullah\n",
    "\n",
    "\n",
    "\n",
    "## 1. <a id='toc1_'></a>[Domain Proyek](#toc0_)\n",
    "\n",
    "Jerawat adalah masalah kulit yang umum terjadi, terutama pada remaja dan dewasa muda. Perawatan jerawat lebih efektif jika dilakukan pada tahap awal perkembangannya. Namun, seringkali sulit untuk mengidentifikasi jerawat pada tahap awal, terutama ketika gejalanya masih subyektif atau kurang mencolok. Oleh karena itu, pengembangan sistem klasifikasi jerawat yang dapat mendeteksi jerawat pada tahap dini sangat penting untuk meningkatkan efektivitas perawatan dan mengurangi dampaknya pada kesehatan mental individu.\n",
    "\n",
    "Dalam upaya untuk meningkatkan kemampuan deteksi dini jerawat, teknologi machine learning dan computer vision menawarkan pendekatan yang menjanjikan. Di dalam domain proyek ini, fokus utama adalah pada penggunaan arsitektur EfficientNet, sebuah model neural network yang terkenal karena efisiensinya dalam memproses gambar dengan kualitas tinggi (Tan & Le, 2019).\n",
    "\n",
    "Arsitektur EfficientNet telah menunjukkan kinerja yang mengesankan dalam berbagai aplikasi pengolahan gambar, termasuk analisis medis seperti deteksi jerawat. Misitzis et al. (2020) menggunakan EfficientNet untuk analisis gambar kulit dalam deteksi dan klasifikasi jerawat dengan akurasi yang tinggi. Penelitian ini menegaskan potensi besar dalam penggunaan teknologi machine learning untuk mendukung diagnosis dini jerawat.\n",
    "\n",
    "Dengan memanfaatkan keunggulan efisiensi dan performa yang ditawarkan oleh EfficientNet, proyek ini bertujuan untuk mengembangkan model klasifikasi dini jerawat yang dapat bekerja secara cepat dan akurat, bahkan pada data gambar kulit yang besar dan kompleks. Melalui penggunaan teknologi ini, diharapkan proyek ini dapat memberikan kontribusi yang signifikan dalam meningkatkan perawatan kesehatan kulit dan kesejahteraan individu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Business Understanding](#toc0_)\n",
    "Jerawat merupakan masalah kulit umum yang dapat mempengaruhi kesehatan mental individu. Diagnosis dini jerawat penting untuk memberikan perawatan yang tepat waktu dan mengurangi dampak negatifnya. Namun, diagnosis jerawat pada tahap awal sering sulit dan dapat menyebabkan penundaan dalam perawatan.\n",
    "\n",
    "Proyek ini bertujuan untuk mengembangkan sistem klasifikasi jerawat menggunakan teknologi machine learning dan computer vision. Dengan membangun model yang efisien dan akurat, proyek ini diharapkan dapat memberikan solusi untuk mendeteksi jerawat pada tahap dini, memungkinkan intervensi lebih awal dan perawatan yang tepat.\n",
    "### 2.1. <a id='toc2_1_'></a>[Problem Statements](#toc0_)\n",
    "Menjelaskan peryataan masalah latar belakang:\n",
    "+ Tantangan Diagnosis Dini Jerawat: Diagnosis jerawat pada tahap awal sering sulit dan tidak konsisten, menyebabkan penundaan dalam perawatan dan memperburuk kondisi kulit.\n",
    "+ Dampak Kesehatan Mental: Jerawat bukan hanya masalah kosmetik, tetapi juga dapat mempengaruhi kesehatan mental dan kesejahteraan individu, terutama remaja dan dewasa muda.\n",
    "+ Perlunya Solusi Otomatis: Pengembangan sistem otomatis untuk klasifikasi dini jerawat menjadi penting untuk meningkatkan akurasi diagnosis dan mengurangi dampak negatifnya.\n",
    "### 2.2. <a id='toc2_2_'></a>[Goals](#toc0_)\n",
    "Menjelaskan tujuan dari pernyataan masalah:\n",
    "+ Pengembangan Model Machine Learning: Membuat model machine learning yang mampu mengenali jerawat pada gambar kulit secara otomatis.\n",
    "+ Tingkatkan Akurasi Model: Memastikan model memiliki tingkat akurasi yang tinggi dalam mengidentifikasi jerawat, bahkan pada gambar kulit yang beragam.\n",
    "+ Solusi Mudah Digunakan: Membuat solusi yang mudah digunakan oleh individu dan profesional kesehatan untuk mendeteksi jerawat pada tahap dini.\n",
    "### 2.3. <a id='toc2_3_'></a>[Solution statements](#toc0_)\n",
    "+ Penggunaan EfficientNet: Memanfaatkan arsitektur neural network EfficientNet yang terkenal karena kemampuannya dalam mengenali pola pada gambar dengan efisien. Model ini akan dilatih menggunakan dataset gambar kulit untuk mengidentifikasi jerawat pada tahap awal dengan tingkat akurasi yang tinggi.\n",
    "+ Rekomendasi Perawatan: Setelah mengenali jerawat pada gambar kulit, model akan memberikan rekomendasi perawatan yang sesuai. Rekomendasi ini akan disesuaikan dengan kondisi kulit individu dan tingkat keparahan jerawat, termasuk penggunaan produk perawatan kulit tertentu atau konsultasi dengan ahli dermatologi.\n",
    "+ Implementasi dalam Aplikasi: Model klasifikasi yang telah dilatih akan diintegrasikan ke dalam sebuah aplikasi mobile yang mudah digunakan. Pengguna dapat dengan mudah mengambil foto kulit mereka sendiri menggunakan kamera ponsel mereka dan mengunggahnya ke aplikasi. Selanjutnya, aplikasi akan menggunakan model untuk mengidentifikasi jerawat pada gambar tersebut dan memberikan rekomendasi perawatan yang tepat.\n",
    "## 3. <a id='toc3_'></a>[Data Understanding](#toc0_)\n",
    "Dataset yang digunakan adalah dataset publik yang diambil dari platform Kaggle, sebuah komunitas online untuk para ahli data dan peneliti. Dataset ini dirancang khusus untuk tujuan pengenalan dan klasifikasi masalah jerawat pada kulit wajah.\n",
    "\n",
    "Dataset ini terdiri dari gambar-gambar yang menampilkan kondisi kulit wajah manusia dengan tiga kelas utama, yaitu jerawat (acne), komedo (pimple), dan bintik hitam (spot). Setiap gambar dalam dataset ini telah dianotasi secara manual untuk mengidentifikasi dan membatasi area di mana jerawat, komedo, atau bintik hitam terdeteksi, menggunakan kotak pembatas (bounding box).\n",
    "### 3.1. <a id='toc3_1_'></a>[Overview Data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Needhi-is-a-Student-from-Sunderpur_-Lakhan_jpg...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>spot</td>\n",
       "      <td>293</td>\n",
       "      <td>388</td>\n",
       "      <td>314</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Needhi-is-a-Student-from-Sunderpur_-Lakhan_jpg...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>spot</td>\n",
       "      <td>379</td>\n",
       "      <td>300</td>\n",
       "      <td>389</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zaleema-Bibi-is-a-Homemaker_-other-occupation-...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>spot</td>\n",
       "      <td>425</td>\n",
       "      <td>327</td>\n",
       "      <td>438</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sushma-Rajput-is-a-Agricultural-labourer-from-...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>pimple</td>\n",
       "      <td>248</td>\n",
       "      <td>189</td>\n",
       "      <td>258</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sushma-Rajput-is-a-Agricultural-labourer-from-...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>acne</td>\n",
       "      <td>273</td>\n",
       "      <td>144</td>\n",
       "      <td>283</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>Nasirun-Bibi-is-a-Homemaker_-other-occupation-...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>acne</td>\n",
       "      <td>269</td>\n",
       "      <td>17</td>\n",
       "      <td>278</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>Nasirun-Bibi-is-a-Homemaker_-other-occupation-...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>spot</td>\n",
       "      <td>420</td>\n",
       "      <td>279</td>\n",
       "      <td>430</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>Nasirun-Bibi-is-a-Homemaker_-other-occupation-...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>spot</td>\n",
       "      <td>229</td>\n",
       "      <td>299</td>\n",
       "      <td>240</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>Nasirun-Bibi-is-a-Homemaker_-other-occupation-...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>spot</td>\n",
       "      <td>233</td>\n",
       "      <td>338</td>\n",
       "      <td>246</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>Nasirun-Bibi-is-a-Homemaker_-other-occupation-...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>spot</td>\n",
       "      <td>172</td>\n",
       "      <td>257</td>\n",
       "      <td>184</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9872 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filename  width  height  \\\n",
       "0     Needhi-is-a-Student-from-Sunderpur_-Lakhan_jpg...    514     514   \n",
       "1     Needhi-is-a-Student-from-Sunderpur_-Lakhan_jpg...    514     514   \n",
       "2     Zaleema-Bibi-is-a-Homemaker_-other-occupation-...    514     514   \n",
       "3     Sushma-Rajput-is-a-Agricultural-labourer-from-...    514     514   \n",
       "4     Sushma-Rajput-is-a-Agricultural-labourer-from-...    514     514   \n",
       "...                                                 ...    ...     ...   \n",
       "1919  Nasirun-Bibi-is-a-Homemaker_-other-occupation-...    514     514   \n",
       "1920  Nasirun-Bibi-is-a-Homemaker_-other-occupation-...    514     514   \n",
       "1921  Nasirun-Bibi-is-a-Homemaker_-other-occupation-...    514     514   \n",
       "1922  Nasirun-Bibi-is-a-Homemaker_-other-occupation-...    514     514   \n",
       "1923  Nasirun-Bibi-is-a-Homemaker_-other-occupation-...    514     514   \n",
       "\n",
       "       class  xmin  ymin  xmax  ymax  \n",
       "0       spot   293   388   314   406  \n",
       "1       spot   379   300   389   316  \n",
       "2       spot   425   327   438   340  \n",
       "3     pimple   248   189   258   198  \n",
       "4       acne   273   144   283   152  \n",
       "...      ...   ...   ...   ...   ...  \n",
       "1919    acne   269    17   278    25  \n",
       "1920    spot   420   279   430   289  \n",
       "1921    spot   229   299   240   307  \n",
       "1922    spot   233   338   246   346  \n",
       "1923    spot   172   257   184   267  \n",
       "\n",
       "[9872 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('../datasets/raw/test/_annotations.csv')\n",
    "train = pd.read_csv('../datasets/raw/train/_annotations.csv')\n",
    "valid = pd.read_csv('../datasets/raw/valid/_annotations.csv')\n",
    "\n",
    "df = pd.concat([test, train, valid])\n",
    "df.to_csv('../datasets/raw/_annotations.csv', index=False)\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for index, item in valid.iterrows():\n",
    "    shutil.copy('../datasets/raw/valid/' + item.filename, '../datasets/raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "acne      4169\n",
       "pimple     643\n",
       "spot      5060\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "counts = df.groupby('class')['class'].count()\n",
    "counts.plot(kind='bar')\n",
    "plt.xlabel('Kelas')\n",
    "plt.ylabel('Jumlah')\n",
    "plt.title('Jumlah Tiap Kelas')\n",
    "\n",
    "# Menampilkan grafik\n",
    "plt.show()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. <a id='toc3_2_'></a>[Analisis Deskriptif](#toc0_)\n",
    "**Analisis pada ukuran gambar**\n",
    "\n",
    "Tabel 1. Analisis deskriptif jumlah ukuran pada tiap-tiap gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>width</th>\n",
       "      <td>512</td>\n",
       "      <td>514</td>\n",
       "      <td>1024</td>\n",
       "      <td>640</td>\n",
       "      <td>1023</td>\n",
       "      <td>900</td>\n",
       "      <td>3112</td>\n",
       "      <td>1000</td>\n",
       "      <td>640</td>\n",
       "      <td>810</td>\n",
       "      <td>...</td>\n",
       "      <td>2084</td>\n",
       "      <td>320</td>\n",
       "      <td>1023</td>\n",
       "      <td>500</td>\n",
       "      <td>799</td>\n",
       "      <td>666</td>\n",
       "      <td>2084</td>\n",
       "      <td>355</td>\n",
       "      <td>487</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>512</td>\n",
       "      <td>514</td>\n",
       "      <td>1024</td>\n",
       "      <td>853</td>\n",
       "      <td>682</td>\n",
       "      <td>1200</td>\n",
       "      <td>3456</td>\n",
       "      <td>1000</td>\n",
       "      <td>852</td>\n",
       "      <td>1080</td>\n",
       "      <td>...</td>\n",
       "      <td>2991</td>\n",
       "      <td>569</td>\n",
       "      <td>878</td>\n",
       "      <td>500</td>\n",
       "      <td>878</td>\n",
       "      <td>883</td>\n",
       "      <td>2990</td>\n",
       "      <td>500</td>\n",
       "      <td>488</td>\n",
       "      <td>2208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6668</td>\n",
       "      <td>1374</td>\n",
       "      <td>234</td>\n",
       "      <td>203</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2    3     4     5     6     7    8     9    ...   99   \\\n",
       "width    512   514  1024  640  1023   900  3112  1000  640   810  ...  2084   \n",
       "height   512   514  1024  853   682  1200  3456  1000  852  1080  ...  2991   \n",
       "count   6668  1374   234  203    53    49    45    35   34    34  ...     4   \n",
       "\n",
       "        100   101  102  103  104   105  106  107   108  \n",
       "width   320  1023  500  799  666  2084  355  487  1218  \n",
       "height  569   878  500  878  883  2990  500  488  2208  \n",
       "count     4     3    3    3    3     3    3    1     1  \n",
       "\n",
       "[3 rows x 109 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['width','height']].value_counts().reset_index(name='count').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabel 2. Analisis deskriptif berdasarkan ukuran gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>width</th>\n",
       "      <td>9872.0</td>\n",
       "      <td>575.829923</td>\n",
       "      <td>242.843667</td>\n",
       "      <td>320.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>3112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>9872.0</td>\n",
       "      <td>603.231058</td>\n",
       "      <td>315.438660</td>\n",
       "      <td>408.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>4047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmin</th>\n",
       "      <td>9872.0</td>\n",
       "      <td>280.371860</td>\n",
       "      <td>144.548506</td>\n",
       "      <td>33.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>2536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ymin</th>\n",
       "      <td>9872.0</td>\n",
       "      <td>306.814830</td>\n",
       "      <td>205.337257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>3351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmax</th>\n",
       "      <td>9872.0</td>\n",
       "      <td>296.086912</td>\n",
       "      <td>149.002759</td>\n",
       "      <td>46.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>2678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ymax</th>\n",
       "      <td>9872.0</td>\n",
       "      <td>321.038493</td>\n",
       "      <td>209.957201</td>\n",
       "      <td>16.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>3434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9872.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std    min    25%    50%    75%     max\n",
       "width   9872.0  575.829923  242.843667  320.0  512.0  512.0  514.0  3112.0\n",
       "height  9872.0  603.231058  315.438660  408.0  512.0  512.0  514.0  4047.0\n",
       "xmin    9872.0  280.371860  144.548506   33.0  201.0  264.0  330.0  2536.0\n",
       "ymin    9872.0  306.814830  205.337257    1.0  177.0  293.0  369.0  3351.0\n",
       "xmax    9872.0  296.086912  149.002759   46.0  215.0  278.0  346.0  2678.0\n",
       "ymax    9872.0  321.038493  209.957201   16.0  189.0  306.0  383.0  3434.0\n",
       "count   9872.0    1.000000    0.000000    1.0    1.0    1.0    1.0     1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['width','height']).value_counts().reset_index(name='count').describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tabel 1 dan 2 dapat disimpulkan sebagai berikut:\n",
    "\n",
    "**Ukuran Gambar:**\n",
    "+ Lebar gambar berkisar antara 320 hingga 3112 piksel, dengan rata-rata sekitar 576 piksel dan standar deviasi sekitar 243 piksel. Ini menunjukkan variasi yang signifikan dalam ukuran gambar, dari yang sangat kecil hingga yang sangat besar.\n",
    "+ Tinggi gambar berkisar antara 408 hingga 4047 piksel, dengan rata-rata sekitar 603 piksel dan standar deviasi sekitar 315 piksel. Variasi yang besar ini menunjukkan variasi yang signifikan dalam dimensi vertikal gambar.\n",
    "\n",
    "**Koordinat Bounding Box (Xmin, Ymin, Xmax, Ymax):**\n",
    "+ Koordinat Xmin dan Ymin menandakan sudut kiri atas dari kotak pembatas objek dalam gambar, sedangkan Xmax dan Ymax menandakan sudut kanan bawah dari kotak pembatas tersebut. Ini memungkinkan untuk membatasi area di mana objek terdeteksi dalam gambar.\n",
    "+ Rata-rata koordinat Xmin adalah sekitar 280 piksel dengan variasi sekitar 145 piksel, sedangkan Ymin adalah sekitar 307 piksel dengan variasi sekitar 205 piksel.\n",
    "+ Rata-rata koordinat Xmax adalah sekitar 296 piksel dengan variasi sekitar 149 piksel, sedangkan Ymax adalah sekitar 321 piksel dengan variasi sekitar 210 piksel.\n",
    "\n",
    "**Gambaran Umum:**\n",
    "+ Jumlah total gambar adalah 9872.\n",
    "+ Gambar terbesar memiliki lebar 3112 piksel dan tinggi 4047 piksel, sedangkan gambar terkecil memiliki lebar 320 piksel dan tinggi 408 piksel.\n",
    "+ Terdapat variasi yang signifikan dalam ukuran gambar, dengan 109 variasi ukuran gambar yang diamati.\n",
    "+ Variasi dalam ukuran gambar tercermin dalam standar deviasi lebar dan tinggi gambar, menunjukkan variasi yang signifikan dari rata-rata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Coords' from 'PIL._typing' (/Users/izzal/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/PIL/_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/torchvision/datasets/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optical_flow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stereo_matching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     CarlaStereo,\n\u001b[1;32m      4\u001b[0m     CREStereo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     SintelStereo,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcaltech\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Caltech101, Caltech256\n",
      "File \u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/torchvision/datasets/_optical_flow.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _read_png_16\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _read_pfm, verify_str_arg\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisionDataset\n",
      "File \u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/torchvision/io/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterator\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_load_gpu_decoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_GPU_VIDEO_DECODER\n",
      "File \u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/torchvision/utils.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageColor, ImageDraw, ImageFont\n\u001b[1;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake_grid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_image\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflow_to_image\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m ]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_grid\u001b[39m(\n\u001b[1;32m     25\u001b[0m     tensor: Union[torch\u001b[38;5;241m.\u001b[39mTensor, List[torch\u001b[38;5;241m.\u001b[39mTensor]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pad_value: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n",
      "File \u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/PIL/ImageDraw.py:40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequence, cast\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageColor\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Coords\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03mA simple 2D drawing interface for PIL images.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m<p>\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03mApplication code should use the <b>Draw</b> factory, instead of\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03mdirectly.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mImageDraw\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Coords' from 'PIL._typing' (/Users/izzal/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/PIL/_typing.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, csv_file, class_list, transform=None):\n",
    "        self.df = csv_file\n",
    "        self.transform = transform\n",
    "        self.class_list = class_list\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.df.filename[index])\n",
    "        label = self.class_list.index(self.df['class'][index])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(df,{'0': 'acne', '1': 'pimple', '2': 'spot'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(fp, mode, formats)\u001b[0m\n",
      "\u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6294\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zj/3c2yfb953rb7s7d7rng5wtb00000gn/T/ipykernel_76440/2184308907.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mFeature batch shape: \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mLabels batch shape: \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mindx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             if self._dataset_kind == _DatasetKind.Iterable and \\\n\u001b[1;32m    634\u001b[0m                     self._IterableDataset_len_called is not None and \\\n",
      "\u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zj/3c2yfb953rb7s7d7rng5wtb00000gn/T/ipykernel_76440/3790069993.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(fp, mode, formats)\u001b[0m\n",
      "\u001b[0;32m~/Repository/klasifikasi-jerawat-efficientNetB4/.venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6293\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6294\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "indx = 0\n",
    "f, axarr = plt.subplots(2, 5, figsize=(12, 8))\n",
    "for r in range(0, 2):\n",
    "  for c in range(0, 5):\n",
    "    img = train_features[indx].squeeze()\n",
    "    label = train_labels[indx]\n",
    "    axarr[r, c].imshow(transforms.ToPILImage()(img))\n",
    "    axarr[r, c].set_title(class_labels_map.get(str(label.item())))\n",
    "    indx+=1"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "17427868/3KWBWDI9": {
     "title": "Waseso and Setiyanto - 2023 - Web Phishing Classification using Combined Machine.pdf",
     "type": "article"
    }
   }
  },
  "kernelspec": {
   "display_name": "klasifikasi-jerawat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
